{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules and specify file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "import glob2\n",
    "import re\n",
    "from openpyxl import load_workbook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Specify paths to files\n",
    "raw_data_path = r'C:\\Users\\MT1070\\Desktop\\Master Call Volume\\raw-report-extracts' \n",
    "\n",
    "# Display names of files in master folder\n",
    "raw_files = glob2.glob(raw_data_path + \"/*.xlsx\")\n",
    "\n",
    "# Initialize an empty data frame to store data from all files\n",
    "final_sheet = pd.DataFrame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data Set and Configure Entry Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively read data extracts from master files and append them to the final DataFrame\n",
    "data_frames = []  # Store DataFrames from master files\n",
    "for file in raw_files:\n",
    "    try:\n",
    "        df = pd.read_excel(file, sheet_name=None, skipfooter=2, engine='openpyxl')\n",
    "        df_concat = pd.concat(df.values(), ignore_index=True, sort=False)\n",
    "        data_frames.append(df_concat)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing file: {file}\")\n",
    "        print(str(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Index and Set Column Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data_frames) > 0:\n",
    "    final_sheet = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Set desired column as \n",
    "\n",
    "final_sheet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Define headers\n",
    "final_sheet.columns = final_sheet.iloc[0]\n",
    "final_sheet = final_sheet[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sheet['department_name']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Date from Datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the values in the \"datetime\" column\n",
    "column_name = 'datetime'\n",
    "if column_name.strip() in final_sheet.columns:\n",
    "    final_sheet[column_name.strip()] = pd.to_datetime(final_sheet[column_name.strip()], format='%m/%d/%y %I:%M:%S %p', errors='coerce')\n",
    "\n",
    "    # Check the data type of the \"datetime\" column after conversion\n",
    "    datetime_column = final_sheet[column_name.strip()]\n",
    "\n",
    "    # Create the 'date' column by extracting month/date/year values\n",
    "    final_sheet['date'] = final_sheet[column_name.strip()].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "    # Print the datetime entries that cannot be parsed\n",
    "    invalid_entries = final_sheet[datetime_column.isna()][column_name.strip()]\n",
    "    print(f\"Invalid datetime entries:\")\n",
    "    print(invalid_entries)\n",
    "\n",
    "else:\n",
    "    print(f\"Column '{column_name.strip()}' not found in the DataFrame.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Entries for Successful & Unsuccessful Calls Transferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful Tools\n",
    "def eval_data_type(column):\n",
    "    data_types = column.apply(type).unique()\n",
    "    \n",
    "    # Print the list of data types found\n",
    "    print(\"Data types found in the column:\")\n",
    "    for data_type in data_types:\n",
    "        print(data_type)\n",
    "\n",
    "    # usage: eval_data_type(final_sheet['valid_department_transfers'])\n",
    "\n",
    "\n",
    "# Count Holistic Metrics\n",
    "total_internal_calls = final_sheet['internal_or_external'].str.count('10030').sum()\n",
    "total_external_calls = final_sheet['internal_or_external'].str.count('10040').sum()\n",
    "total_calls = total_internal_calls + total_external_calls\n",
    "\n",
    "output_holistic_metrics = False\n",
    "if output_holistic_metrics:\n",
    "    print(f\"Total number of internal calls: {total_internal_calls}\")\n",
    "    print(f\"Total number of external calls: {total_external_calls}\")\n",
    "    print(f\"Total number of calls: {total_calls}\\n\\n\")\n",
    "\n",
    "\n",
    "# Count number of successful workflows\n",
    "first_try_success = final_sheet['department_utternace_first_try_success'].count()\n",
    "second_try_success = final_sheet['department_utternace_second_try_success'].count()\n",
    "third_try_success = final_sheet['department_utternace_second_try_success'].count()\n",
    "total_success = first_try_success + second_try_success + third_try_success\n",
    "\n",
    "\n",
    "# Output Successful Counts\n",
    "output_successful_counts = True\n",
    "if output_successful_counts:\n",
    "    print(f\"Number of entries in First Try Success: {first_try_success}\")\n",
    "    print(f\"Number of entries in Second Try Success: {second_try_success}\")\n",
    "    print(f\"Number of entries in Third Try Success: {third_try_success}\")\n",
    "    print(f\"Total number of successful call transfers: {total_success}\\n\")\n",
    "\n",
    "\n",
    "# Count number of unsuccessful workflows\n",
    "first_nomatch = final_sheet['department_utternace_first_nomatch'].count()\n",
    "second_nomatch = final_sheet['department_utternace_second_nomatch'].count()\n",
    "third_nomatch = final_sheet['department_utternace_third_nomatch'].count()\n",
    "final_nomatch = final_sheet['department_utternace_max_nomatch'].count()\n",
    "total_nomatch = first_nomatch + second_nomatch + third_nomatch + final_nomatch\n",
    "\n",
    "# Output Usuccessful Counts\n",
    "output_unsuccessful_counts = False\n",
    "if output_unsuccessful_counts:\n",
    "    print(f\"Number of unsuccessful first try entries: {first_nomatch}\")\n",
    "    print(f\"Number of unsuccessful second try entries: {second_nomatch}\")\n",
    "    print(f\"Number of unsuccessful third try entries: {third_nomatch}\")\n",
    "    print(f\"Total number of unsuccessful calls: {total_nomatch}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpinSci Metrics Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'call_transfer_success'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\MT1070\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\MT1070\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\MT1070\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'call_transfer_success'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MT1070\\Mass General Brigham\\MTurra Internal - General\\Project Managing\\python-practice\\work-work\\raw-data-handling.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MT1070/Mass%20General%20Brigham/MTurra%20Internal%20-%20General/Project%20Managing/python-practice/work-work/raw-data-handling.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# SpinSci Metric Verification\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MT1070/Mass%20General%20Brigham/MTurra%20Internal%20-%20General/Project%20Managing/python-practice/work-work/raw-data-handling.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# What to expect from the dataset\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MT1070/Mass%20General%20Brigham/MTurra%20Internal%20-%20General/Project%20Managing/python-practice/work-work/raw-data-handling.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m eval_data_type(final_sheet[\u001b[39m'\u001b[39;49m\u001b[39mcall_transfer_success\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MT1070/Mass%20General%20Brigham/MTurra%20Internal%20-%20General/Project%20Managing/python-practice/work-work/raw-data-handling.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Count Successful and Unsuccessful Calls\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MT1070/Mass%20General%20Brigham/MTurra%20Internal%20-%20General/Project%20Managing/python-practice/work-work/raw-data-handling.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m spinsci_success_count \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(final_sheet[\u001b[39m'\u001b[39m\u001b[39mcall_transfer_success\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcount(\u001b[39m'\u001b[39m\u001b[39m10050\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39msum())\n",
      "File \u001b[1;32mc:\\Users\\MT1070\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\MT1070\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'call_transfer_success'"
     ]
    }
   ],
   "source": [
    "# SpinSci Metric Verification\n",
    "# What to expect from the dataset\n",
    "eval_data_type(final_sheet['call_transfer_success'])\n",
    "\n",
    "# Count Successful and Unsuccessful Calls\n",
    "spinsci_success_count = int(final_sheet['call_transfer_success'].str.count('10050').sum())\n",
    "non_transfers = final_sheet['call_transfer_success'].isna().sum()\n",
    "verify_with_total_calls = spinsci_success_count + non_transfers\n",
    "\n",
    "# Output results\n",
    "print(f\"Total number of calls based on internal and external entries: {total_calls}\")\n",
    "print(f\"Calculated total number of calls: {verify_with_total_calls}\")\n",
    "print(f\"Number of successful transfers: {spinsci_success_count}\")\n",
    "print(f\"Number of unsuccessful transfers: {non_transfers}\\n\\n\")\n",
    "\n",
    "# Extract dataframe with metrics of all successful calls\n",
    "success_filter = final_sheet['call_transfer_success'].str.contains('10050') & final_sheet['call_transfer_success'].notna()\n",
    "successful_calls = final_sheet[success_filter].copy()\n",
    "\n",
    "\n",
    "# Count the number of Operator requests\n",
    "option2_name = '(menuoption2)'\n",
    "option3_name = '(menuoption3)'\n",
    "option4_name = '(menuoption4)'\n",
    "option5_name = '(menuoption5)'\n",
    "option0_name = '(press 0)'\n",
    "trailing_operator_pattern = r'^operator(?!.*\\(.*\\))'\n",
    "\n",
    "list_of_options = [option2_name, option3_name, option4_name, option5_name, option0_name]\n",
    "\n",
    "option2_selection = successful_calls['department_name'].str.count(option2_name).sum()\n",
    "option3_selection = successful_calls['department_name'].str.count(option3_name).sum()\n",
    "option4_selection = successful_calls['department_name'].str.count(option4_name).sum()\n",
    "option5_selection = successful_calls['department_name'].str.count(option5_name).sum()\n",
    "option0_selection = successful_calls['department_name'].str.count(option0_name).sum()\n",
    "\n",
    "print(f\"Total number of callers selecting option 2: {option2_selection}\")\n",
    "print(f\"Total number of callers selecting option 3: {option3_selection}\")\n",
    "print(f\"Total number of callers selecting option 4: {option4_selection}\")\n",
    "print(f\"Total number of callers selecting option 5: {option5_selection}\")\n",
    "print(f\"Total number of callers selecting option 0: {option0_selection}\")\n",
    "\n",
    "# Count the number of non-Operator requests\n",
    "non_operator_requests = (~successful_calls['department_name'].isin(list_of_options)).sum()\n",
    "requests_total = non_operator_requests + option2_selection + option3_selection + option4_selection + option5_selection + option0_selection\n",
    "print(f\"The number of non-Operator requests were: {non_operator_requests}\")\n",
    "print(f\"Total number of calls based on call breakdown: {requests_total}\")\n",
    "\n",
    "print(successful_calls['department_name'])\n",
    "\n",
    "spinsci_calc_metrics = False\n",
    "if spinsci_calc_metrics:\n",
    "    spinsci_percent_success_transfers = int((spinsci_success_count/total_calls)*100)\n",
    "    calc_percent_success = int((total_success/total_calls)*100)\n",
    "\n",
    "    print(f\"Total number of SpinSci ID'd successful call transfers: {spinsci_success_count}\")\n",
    "    print(f\"Percentage of successful calls transfered: {spinsci_percent_success_transfers}%\")\n",
    "    print(f\"Calc. Percentage of successful calls transfered: {calc_percent_success}%\\n\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Datatypes in department_name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_values = final_sheet.loc[final_sheet['department_name'].apply(lambda x: isinstance(x, float)), 'department_name']\n",
    "\n",
    "print(\"Float values in the column:\")\n",
    "print(float_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change department_name entries format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String manipulation to modify department_name entries\n",
    "count_department_tranfers = final_sheet['department_name'].count()\n",
    "print(f\"The total number entries in Department Name column: {count_department_tranfers}\\n\")\n",
    "print(\"Breakdown of Department Transfers Column:\")\n",
    "\n",
    "# Count the number of NaN entries in department_name\n",
    "print(f\"Total number of calls: {total_calls}\\n\\n\")\n",
    "nonconclusive_transfers = final_sheet['department_name'].isna().sum()\n",
    "print(f\"Number of non-transfers: {nonconclusive_transfers}\")\n",
    "\n",
    "# Create a new column with non-NaN entries from 'column_name'\n",
    "final_sheet['valid_department_transfers'] = final_sheet['department_name'].fillna('')\n",
    "\n",
    "# Change department_name to str type\n",
    "final_sheet['valid_department_transfers'] = final_sheet['valid_department_transfers'].astype(str)\n",
    "# dtype = final_sheet['valid_department_transfers'].dtype\n",
    "# print(f\"The format for department_name column: {dtype}\")\n",
    "\n",
    "# Count number of entries without \"Operator\"\n",
    "count_non_operator = final_sheet['valid_department_transfers'].str.contains('Operator', case=False, na=False).sum()\n",
    "# count_no\n",
    "\n",
    "print(f\"Number of requests that are not the Operator {count_non_operator}\")\n",
    "\n",
    "# Print the DataFrame to see the updated column\n",
    "# print(final_sheet['valid_department_transfers'])\n",
    "\n",
    "\n",
    "operator_selections = final_sheet['valid_department_transfers'].str.count('Operator').sum()\n",
    "print(f\"Total number of Operator Selections: {operator_selections}\\n\\n\")\n",
    "# misc_selection = final_sheet['department_name'].str.count('Operator(press 0)').sum()\n",
    "# count_department_tranfers = final_sheet['department_name'].count()\n",
    "\n",
    "\n",
    "# Department Column Transfer Check. Total same as spinsci_success_count\n",
    "# final_sheet['department_name'] = final_sheet['department_name'].astype('str')\n",
    "\n",
    "    # Verify the data type of entries in the target column\n",
    "# print(final_sheet['department_name'].dtype)\n",
    "\n",
    "# unique_values = final_sheet['department_name'].unique()\n",
    "# print(unique_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graveyard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate Invalid Entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'datetime'\n",
    "if column_name.strip() in final_sheet.columns:\n",
    "    final_sheet[column_name.strip()] = pd.to_datetime(final_sheet[column_name.strip()], format='%m/%d/%y %I:%M:%S %p', errors='coerce')\n",
    "\n",
    "    # Check the data type of the \"datetime\" column after conversion\n",
    "    datetime_column = final_sheet[column_name.strip()]\n",
    "    data_type = datetime_column.dtype\n",
    "    print(f\"The data type of elements in the '{column_name}' column after conversion is: {data_type}\")\n",
    "\n",
    "    # Print the datetime entries that cannot be parsed\n",
    "    invalid_entries = final_sheet[datetime_column.isna()][column_name.strip()]\n",
    "    print(f\"Invalid datetime entries:\")\n",
    "    print(invalid_entries)\n",
    "\n",
    "# Utilize the output of the script above to find the NaN values.\n",
    "index_value = 2978\n",
    "print(final_sheet.iloc[index_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(df, column_name):\n",
    "    if column_name in df.columns:\n",
    "        if column_name == 'datetime':\n",
    "            try:\n",
    "                df['Date'] = df[column_name].dt.date\n",
    "                # df[column_name] = pd.to_datetime(df[column_name], format='%m/%d/%y %I:%M:%S %p')\n",
    "                return df\n",
    "            except ValueError:\n",
    "                print(f\"Invalid datetime format in column {column_name}:\")\n",
    "                print(df[column_name])\n",
    "        else:\n",
    "            df[column_name] = pd.to_datetime(df[column_name], format='%m/%d/%y %I:%M:%S %p')\n",
    "            return df\n",
    "    else:\n",
    "        print(f\"Column '{column_name} not found in Dataframe.\")\n",
    "        return None\n",
    "    \n",
    "final_sheet = convert_to_datetime(final_sheet, 'datetime')\n",
    "\n",
    "# print(final_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
